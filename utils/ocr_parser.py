import cv2
import easyocr
import numpy as np
from PIL import Image
from typing import Union
from paddleocr import PaddleOCR
from matplotlib import pyplot as plt

reader = easyocr.Reader(['en'])
paddle_ocr = PaddleOCR(lang='en', text_det_limit_side_len=1024, text_det_limit_type='max')  # optimized configuration for better detection

def get_xywh(input):
    x, y, w, h = input[0][0], input[0][1], input[2][0] - input[0][0], input[2][1] - input[0][1]
    x, y, w, h = int(x), int(y), int(w), int(h)
    return x, y, w, h

def get_xyxy(input):
    x, y, xp, yp = input[0][0], input[0][1], input[2][0], input[2][1]
    x, y, xp, yp = int(x), int(y), int(xp), int(yp)
    return x, y, xp, yp

def check_ocr_box(image_source: Union[str, Image.Image], display_img = True, output_bb_format='xywh', goal_filtering=None, easyocr_args=None, use_paddleocr=False):
    if isinstance(image_source, str):
        image_source = Image.open(image_source)
    if image_source.mode == 'RGBA':
        # Convert RGBA to RGB to avoid alpha channel issues
        image_source = image_source.convert('RGB')
    image_np = np.array(image_source)
    w, h = image_source.size
    if use_paddleocr:
        if easyocr_args is None:
            text_threshold = 0.5
        else:
            text_threshold = easyocr_args['text_threshold']
        # PaddleOCR 3.3.2: Use ocr() method with optimized parameters
        import warnings
        warnings.filterwarnings('ignore', category=DeprecationWarning)
        result = paddle_ocr.ocr(image_np)[0]
        # Extract coordinates and text from new format
        coord = []
        text = []
        for i, score in enumerate(result['rec_scores']):
            if score > text_threshold:
                coord.append(result['dt_polys'][i])
        if easyocr_args is None:
            easyocr_args = {}
        result = reader.readtext(image_np, **easyocr_args)
        coord = [item[0] for item in result]
        text = [item[1] for item in result]
    if display_img:
        opencv_img = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
        bb = []
        for item in coord:
            x, y, a, b = get_xywh(item)
            bb.append((x, y, a, b))
            cv2.rectangle(opencv_img, (x, y), (x+a, y+b), (0, 255, 0), 2)
        #  matplotlib expects RGB
        plt.imshow(cv2.cvtColor(opencv_img, cv2.COLOR_BGR2RGB))
    else:
        if output_bb_format == 'xywh':
            bb = [get_xywh(item) for item in coord]
        elif output_bb_format == 'xyxy':
            bb = [get_xyxy(item) for item in coord]
    return (text, bb), goal_filtering

if __name__ == '__main__':
    image_path = "./tests/tmp.png"
    image_input = Image.open(image_path).convert('RGB')

    ocr_bbox_rslt, _ = check_ocr_box(
        image_input,
        display_img=False,
        output_bb_format='xyxy',
        goal_filtering=None,
        easyocr_args={'paragraph': False, 'text_threshold': 0.9},
        use_paddleocr=True
    )
    text, ocr_bbox = ocr_bbox_rslt
    for i, j in enumerate(zip(text, ocr_bbox)):
        print(f"Text: {i}, OCR BBox: {j}")
